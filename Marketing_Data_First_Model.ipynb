{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTqteW6d7vEfoqEyL3oGJp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaronszypulagastro/Marketing-Optimizer-Gaming-Industry-/blob/main/Marketing_Data_First_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeEQqWCqpjUp",
        "outputId": "069cd069-725d-4043-e6a0-6a5dd3bfd097"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using:\n",
            " pandas 2.2.2\n",
            "- sklearn ready\n",
            "- tensorflow 2.19.0\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, sys, random, warnings\n",
        "from pathlib import Path\n",
        "\n",
        "#Visualiserung\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(style='whitegrid') # globaler stil: weiß\n",
        "\n",
        "# SCKIT LEARN: PIPELINE UND PREPROCESSING\n",
        "\n",
        "  # Daten aufteilen in train/test, cross val berechnen\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "  # Nützlich für unterschiedliche preprocessing schritte in einem objekt\n",
        "from sklearn.compose import ColumnTransformer\n",
        "  # Kettet schritte (imputer , encoder/scaler, modell) zu einem sauberen workflow\n",
        "from sklearn.pipeline import Pipeline\n",
        "  # Dummy-Spalten, standartscaler für nomierte skala\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "  # Fehlwerte auffüllen\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# SCIKIT LEARN: MODELLE UND METRIKEN\n",
        "\n",
        "  # Einfaches klassifikationsmodell\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "  # Ensemble-bäume für Klassifikation und Regression\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "  # Metrics\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, f1_score, roc_auc_score, confusion_matrix, classification_report,\n",
        "    mean_absolute_error, mean_squared_error, r2_score\n",
        ")\n",
        "\n",
        "# MODELLE SPEICHERN\n",
        "import joblib\n",
        "\n",
        "# Warnungen und Reproduzierbarkeit\n",
        "  # Erster Seed (beliebige Zahl)\n",
        "SEED = 42\n",
        "  # Setzt Zufallsgeneratoren in Python, NumPy und TensorFlow\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "  # Unterdrückt Warnungen (enfernen beim Debugging :)\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# PFADE\n",
        "  # Arbeitsverzeichnis\n",
        "PROJECT_DIR = Path.cwd()\n",
        "  # Pfad zusammensetzen via '/'-Operator\n",
        "DATA_DIR = PROJECT_DIR / 'data'\n",
        "  # Zielordner für Grafiken/Modelle/Reports\n",
        "RESULTS_DIR = PROJECT_DIR / 'results'\n",
        "  # Legt results/ an falls nicht vorhanden\n",
        "RESULTS_DIR.mkdir(exist_ok=True, parents=True)\n",
        "  # Kurzer Versionscheck\n",
        "print(f'Using:\\n pandas {pd.__version__}\\n- sklearn ready\\n- tensorflow {tf.__version__}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3XpDg_QI147a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Einfügen der CSV_Datei\n",
        "DATA_PATH = '/content/Social_Media_Advertising.csv'\n",
        "\n",
        "# CSV einlesen\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "\n",
        "# Form und erste Zeilen prüfen\n",
        "print('Shape:', df.shape) # Zeile, Spalten\n",
        "print(df.head()) # Erste Zeilen\n",
        "print(df.dtypes) # Datentype pro Spalte"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44VI7LP4ypYK",
        "outputId": "203950e3-9a5d-4909-a681-6a329648dedf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (300000, 16)\n",
            "   Campaign_ID Target_Audience  ...        Date         Company\n",
            "0       529013       Men 35-44  ...  2022-02-25      Aura Align\n",
            "1       275352     Women 45-60  ...  2022-05-12  Hearth Harmony\n",
            "2       692322       Men 45-60  ...  2022-06-19   Cyber Circuit\n",
            "3       675757       Men 25-34  ...  2022-09-08       Well Wish\n",
            "4       535900       Men 45-60  ...  2022-08-24  Hearth Harmony\n",
            "\n",
            "[5 rows x 16 columns]\n",
            "Campaign_ID           int64\n",
            "Target_Audience      object\n",
            "Campaign_Goal        object\n",
            "Duration             object\n",
            "Channel_Used         object\n",
            "Conversion_Rate     float64\n",
            "Acquisition_Cost     object\n",
            "ROI                 float64\n",
            "Location             object\n",
            "Language             object\n",
            "Clicks                int64\n",
            "Impressions           int64\n",
            "Engagement_Score      int64\n",
            "Customer_Segment     object\n",
            "Date                 object\n",
            "Company              object\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Zielvariable definieren\n",
        "\n",
        "# Schwelle definieren (hier 5% Conversion-Rate als Beispiel)\n",
        "threshold = 0.05\n",
        "\n",
        "df['Success'] = (df['Conversion_Rate'] >= threshold).astype(int)\n",
        "\n",
        "print(df['Success'].value_counts(normalize=True)) # Wie viel Prozent der Kampagne war erfolgreich?\n",
        "print(df[['Conversion_Rate', 'Success']].head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkiHUCfA3Att",
        "outputId": "f7e4455a-3ca5-4079-ef86-d11b1f5e70e0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success\n",
            "1    0.750603\n",
            "0    0.249397\n",
            "Name: proportion, dtype: float64\n",
            "   Conversion_Rate  Success\n",
            "0             0.15        1\n",
            "1             0.01        0\n",
            "2             0.08        1\n",
            "3             0.03        0\n",
            "4             0.13        1\n",
            "5             0.02        0\n",
            "6             0.10        1\n",
            "7             0.10        1\n",
            "8             0.14        1\n",
            "9             0.04        0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Features (X) und Ziel (y)\n",
        "\n",
        "# Spalten die wir NICHT als Input nutzen (IDs, Zielspalten)\n",
        "\n",
        "  # Modell 'rät' die schwelle wenn Conversion_Rate drin belibt\n",
        "drop_cols = ['Campaign_ID', 'Company', 'Date', 'Conversion_Rate', 'Success' ]\n",
        "\n",
        "# Features (X) und Zielvariable (y) definieren\n",
        "X = df.drop(drop_cols, axis=1)\n",
        "y = df['Success']\n",
        "\n",
        "print('X shape:', X.shape)\n",
        "print('y shape:', y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kR2Y0WsF448n",
        "outputId": "a57068f9-4fd4-4fa5-aa87-29436df9c7f4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (300000, 13)\n",
            "y shape: (300000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_honest, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print('Train size:', X_train.shape, 'Test size:', X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogESnaEZ64ig",
        "outputId": "16d17152-7049-4310-d91b-7da4de5bd1c6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: (240000, 7) Test size: (60000, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing-Pipeline\n",
        "\n",
        "# 1) Spalten nach Typ trennen\n",
        "cat_cols = X_honest.columns.tolist()\n",
        "\n",
        "print('Kategorisch:', cat_cols)\n",
        "\n",
        "\n",
        "# 2) Pipeline für kategorische Spalten\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')), # fehlende Werte durch Modalwert ersetzen\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore')) # One-Hot-Encoding (z.B. 'Instagram'zu 0/1 Spalten )\n",
        "])\n",
        "\n",
        "# 3) Alles zusammenbauen\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=\n",
        "    [\n",
        "    ('cat', categorical_transformer, cat_cols)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQK02rB17vrK",
        "outputId": "95372948-2d62-43e3-fb00-2153db0a7507"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kategorisch: ['Target_Audience', 'Campaign_Goal', 'Duration', 'Channel_Used', 'Location', 'Language', 'Customer_Segment']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression als erstes Baseline-Modell\n",
        "\n",
        "# Pipeline + Modell kombinieren\n",
        "clf = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', LogisticRegression(max_iter=1000))\n",
        "])\n",
        "\n",
        "# Modell trainieren\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Vorhersagen\n",
        "y_pred = clf.predict(X_test)\n",
        "y_proba = clf.predict_proba(X_test)[:, 1] # für ROC-AUC"
      ],
      "metadata": {
        "id": "rL0mVljI-yxF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "\n",
        "# Accuracy\n",
        "print('Accuracy', accuracy_score(y_test, y_pred))\n",
        "\n",
        "# F1-Score (besser bei unbalancierten Klassen)\n",
        "print('F1-Score', f1_score(y_test, y_pred))\n",
        "\n",
        "# ROC-AUC\n",
        "print('ROC-AUC', roc_auc_score(y_test, y_proba))\n",
        "\n",
        "# Confusion Matrix\n",
        "print('Confusion Matrix\\n', confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Classification Report (Precision, Recall, F1 pro Klasse)\n",
        "print('\\nClassification Report:\\n', classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Li0Bf-Q7BboJ",
        "outputId": "9a86218b-fadd-4869-c740-3f2f24333854"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.7506\n",
            "F1-Score 0.8575345595795727\n",
            "ROC-AUC 0.5022733276148987\n",
            "Confusion Matrix\n",
            " [[    0 14964]\n",
            " [    0 45036]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00     14964\n",
            "           1       0.75      1.00      0.86     45036\n",
            "\n",
            "    accuracy                           0.75     60000\n",
            "   macro avg       0.38      0.50      0.43     60000\n",
            "weighted avg       0.56      0.75      0.64     60000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fazit1.1: Vermutlicher Data Leakage, an was liegt das? Im ersten Versuch mit allen Features erzielte das Modell eine perfekte Accuracy von 1.0. Das war jedoch ein Hinweis auf Data Leakage, da Variablen wie ROI oder Acquisition_Cost direkt mit der Zielgröße Conversion_Rate zusammenhängen. Damit war das Modell zwar mathematisch „perfekt“, aber praktisch nicht realistisch einsetzbar**\n",
        "\n",
        "**Fazit1.2: Im zweiten Versuch wurden nur „ehrliche“ Features genutzt, die vor Kampagnenstart bekannt sind (z. B. Zielgruppe, Kanal, Sprache, Segment). Dadurch sank die Modell-Performance auf ca. 75 % Accuracy, aber dieses Ergebnis ist realistisch und praxisrelevant. Es zeigt, dass die Auswahl von Zielgruppe, Kanal oder Kampagnenziel einen messbaren Einfluss auf den Erfolg hat – auch wenn das Modell die „nicht erfolgreichen“ Kampagnen aktuell noch schlecht unterscheidet.**"
      ],
      "metadata": {
        "id": "EGL8TrhCDKSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wir nehmen nur ehrliche Features (keine 'Outcome'-Variablen)\n",
        "honest_features = [\n",
        "    'Target_Audience', 'Campaign_Goal', 'Duration',\n",
        "    'Channel_Used', 'Location', 'Language', 'Customer_Segment'\n",
        "]\n",
        "\n",
        "X_honest = df[honest_features]\n",
        "y = df['Success']\n",
        "\n",
        "print('Neue Feature-Shape:', X_honest.shape)\n",
        "print('y distribution:', y.value_counts(normalize=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fgldBBAC8xJ",
        "outputId": "09989e44-a4b1-45d0-baea-df04c9da93da"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neue Feature-Shape: (300000, 7)\n",
            "y distribution: Success\n",
            "1    0.750603\n",
            "0    0.249397\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Nächste Schritte:\n",
        "# Training meherer Modelle auf denselben Preprocessing Schritten und denselben Daten\n",
        "# Ziel: Faire, vergleichbare Metriken\n",
        "# Guter Vergleich welches Modell mit den Features performt\n",
        "\n",
        "from xgboost import XGBClassifier #Gradient Boosting\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report\n",
        "\n",
        "models = {\n",
        "    'LogReg {balanced}': LogisticRegression(class_weight='balanced', max_iter=1000),\n",
        "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'XGBoost (balanced)': XGBClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=5,\n",
        "        learning_rate=0.1,\n",
        "        scale_pos_weight=0.33,  # Ungleichgewicht ausgleichen\n",
        "        use_label_encoder=False,\n",
        "        eval_metric=\"logloss\",\n",
        "        random_state=42\n",
        "    )\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "  clf = Pipeline(\n",
        "      steps=[\n",
        "          ('preprocessor', preprocessor),\n",
        "          ('model', model)\n",
        "  ])\n",
        "\n",
        "  # Training\n",
        "  clf.fit(X_train, y_train)\n",
        "\n",
        "  # Vorhersagen\n",
        "  y_pred = clf.predict(X_test)\n",
        "  y_proba = clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "  # Metriken speichern\n",
        "  results[name] = {\n",
        "      'Accuracy': accuracy_score(y_test, y_pred),\n",
        "      'F1-Score': f1_score(y_test, y_pred),\n",
        "      'ROC-AUC': roc_auc_score(y_test, y_proba)\n",
        "  }\n",
        "\n",
        "  print(f'\\n==== {name} ====')\n",
        "  print('Accuracy:', results[name]['Accuracy'])\n",
        "  print('F1-Score:', results[name]['F1-Score'])\n",
        "  print('ROC-AUC:', results[name]['ROC-AUC'])\n",
        "  print('\\nClassification Report:\\n', classification_report(y_test, y_pred))\n",
        "\n",
        "# Übersichtliche Tabelle\n",
        "results_df = pd.DataFrame(results).T\n",
        "print('\\n=== Modellvergleich ===')\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxwowsiGILTB",
        "outputId": "783b6bdc-1d84-464b-e7f4-172e7dc10862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==== LogReg {balanced} ====\n",
            "Accuracy: 0.5101166666666667\n",
            "F1-Score: 0.6140878356200354\n",
            "ROC-AUC: 0.5022398918312261\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      0.48      0.33     14964\n",
            "           1       0.75      0.52      0.61     45036\n",
            "\n",
            "    accuracy                           0.51     60000\n",
            "   macro avg       0.50      0.50      0.47     60000\n",
            "weighted avg       0.63      0.51      0.54     60000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FAZIT:\n",
        "Logistic Regression: zu simpel → liefert Zufallsergebnisse.\n",
        "\n",
        "Random Forest: liefert aktuell die sinnvollsten Ergebnisse → erkennt Muster, beide Klassen werden besser behandelt.\n",
        "\n",
        "XGBoost: wirkt super, aber nur, weil es die Mehrheitsklasse bevorzugt. Ohne Anpassung (z. B. scale_pos_weight) ist es nicht vertrauenswürdig.**\n",
        "\n"
      ],
      "metadata": {
        "id": "xPl_vCQHV-7n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Nächster Schritt:\n",
        "Einbau scale_pos_weight\n",
        "und Bäume verringern da nicht genug Rechenleistung (dauert zu lange :( )**"
      ],
      "metadata": {
        "id": "qnuBlPJvXgQf"
      }
    }
  ]
}